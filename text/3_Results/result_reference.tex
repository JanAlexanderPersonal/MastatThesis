\chapter{Reference model\label{sec:reference_model}}\thispagestyle{empty}
\par{
    As a reference to compare the models trained on weakly supervised data with, the model performance of a model trained on the same fully supervised data is taken as a reference.
    In this chapter, the results of these fully supervised reference experiments are discussed.
    The metric based on which the experiment results are compared is the inverse class weighted dice score, see equation \ref{eq:weighted_dice} on page \pageref{eq:weighted_dice}.
}


\section{Experiment results}
\par{
    The fully supervised experiments serve two goals.
    The first is to calculate a reference model performance with which to compare the weakly supervised model results.
    The second is to support hyperparameter choices for the point supervised experiments.
    It is assumed that a network architecture that yields a good, fully supervised model is also a suitable choice to build a weakly supervised model.
    The possible influence of the context slices\footnote{The context slice idea is discussed in detail in chapter \ref{section:twoDplus} on page \pageref{section:twoDplus}.} is also evaluated with these experiments.
}



\par{
    In figure \ref{fig:referenceExperiments}, the results of the reference experiments are shown.
    These results show that the network based on VGG16 yields better results than the alternatives based on RESNET50 and U-Net.
    Despite what was hoped for, the context slices do not seem to increase the model performance.
    Remarkably, there is little difference between the models trained with a weighted cross-entropy loss and the non-weighted cross-entropy loss\footnote{
        The weighted cross-entropy loss is defined in chapter \ref{sec:crossentropy} on page \pageref{sec:crossentropy}. 
        The objective of a weighted cross-entropy is to improve the model performance for under-represented classes in an unbalanced dataset by adding a factor inverse proportional to the class prevalence to the cross-entropy loss.
    } when considering the weighted dice score.
    In figure \ref{fig:referenceWeighted}, the model result based on the FCN8 VGG16 model without context slices is compared in detail for the models trained with weighted and the unweighted cross-entropy function.
    Based on these images, some conclusions can be drawn:
    \begin{enumerate}
        \item The prediction of the background class is practically perfect for all datasets.
        \item Other authors \cite{Lessmann2018,Chuang2019} required elaborate evaluation schemes to be able to label the segmented lumbar vertebrae. 
        Due to the larger view ($352 mm \times 352 mm$ vs $180 mm \times 180 mm \times 180 mm$) this model can use by working with 2D slices, it is possible to have all vertebrae in one image.
        The latter proves to allow the model to be trained to identify all five lumbar vertebrae without requiring the evaluation scheme.
        Observe that $\mathcal{P}(C = Li \mid pred = Lj)$ is low for $i\neq j$.
    \end{enumerate}
}
\begin{SCtable}[\sidecaptionrelwidth][h]
    \begin{tabular}{l|llll}
        \toprule
        & \textbf{precision} & \textbf{recall} & \textbf{dice} & \textbf{iou} \\ \hline
        \textbf{Background} & 99.9\%             & 99.7\%          & 99.8\%        & 99.6\%       \\
        \textbf{L1}         & 55.8\%             & 84.0\%          & 67.1\%        & 50.5\%       \\
        \textbf{L2}         & 70.2\%             & 85.2\%          & 77.0\%        & 62.6\%       \\
        \textbf{L3}         & 77.8\%             & 79.9\%          & 78.8\%        & 65.1\%       \\
        \textbf{L4}         & 74.0\%             & 83.2\%          & 78.3\%        & 64.4\%       \\
        \textbf{L5}         & 72.8\%             & 88.2\%          & 79.7\%        & 66.3\%      \\
        \bottomrule
        \end{tabular}
    
        \caption{Per class metric results for the reference model. 
        The performance metrics on the background class are invariably excellent. There are about 500 background pixels for each class pixel. The data is not balanced.
        Using the inversely weighted dice score gives more weight to the underrepresented classes, which are more of interest.
        \label{tab:full_performanceTable}
        }
    \end{SCtable}
The model trained with an unweighted cross-entropy loss underperforms compared to the model trained with the weighted cross-entropy loss to predict the $L1$ class.
For the other classes, the conclusion based on the inverse weighted dice score holds.

\begin{SCfigure}[][htb]
    \centering
    \includegraphics[width=.98\textwidth]{images/FullySupervised.pdf}
    \caption{Results of the fully supervised experiments.
    The indicated model performance metrics are calculated on the test set.
    The columns represent de weighted dice scores for models based on the same network architecture with different loss functions.
    \label{fig:referenceExperiments}}
\end{SCfigure}

\begin{SCfigure}[][htb]
    \centering
    \begin{minipage}{.98\textwidth}
        \includegraphics[width=.98\textwidth]{images/full_perClass_perSource_weighted.pdf}
    \end{minipage} 
    \begin{minipage}{0.98\textwidth}
        \includegraphics[width=.98\textwidth]{images/full_perClass_perSource_notweighted.pdf}
    \end{minipage}
    \caption{Detailed result for the fully supervised model trained without context slices and with a weighted cross entropy loss function.
    The model trained with the unweighted loss performs better than the result shown in figure \ref{fig:referenceWeighted} for the weighted cross entropy loss function.
    \input{tables/colourlegend_long.tex}
    \label{fig:referenceWeighted} 
    }
\end{SCfigure}
\begin{SCtable}[\sidecaptionrelwidth][h]
 
\begin{tabular}{cl|llllll}
    \toprule
    \multicolumn{2}{l|}{\multirow{2}{*}{values in {[}\%{]}}} & \multicolumn{6}{c}{\textbf{Predicted}}                                            \\
    \multicolumn{2}{l|}{}                                    & \textbf{BG} & \textbf{L1} & \textbf{L2} & \textbf{L3} & \textbf{L4} & \textbf{L5} \\ \hline
    \multirow{6}{*}{\textbf{Actual}}      & \textbf{BG}      & 99.9        & 13.2        & 14.5        & 14.2        & 12.9        & 12.1        \\
     & \textbf{L1} & 0 & 86.6 & 2.1  & 0.1  & 0.2  & 0    \\
     & \textbf{L2} & 0 & 0.2  & 83.4 & 0.9  & 0.1  & 0    \\
     & \textbf{L3} & 0 & 0    & 0.1  & 83.9 & 0.4  & 0    \\
     & \textbf{L4} & 0 & 0    & 0    & 1    & 86.1 & 0.7  \\
     & \textbf{L5} & 0 & 0    & 0    & 0    & 0.3  & 87.2 \\ \bottomrule
    \end{tabular}

    \caption{Confusion matrix for the model trained with full label masks (network VGG16-FCN8 and cross-correlation loss), evaluated on the test set.
    The values have been normalized by the total number of voxels predicted in each class.
    The diagonal elements are thus the class precisions: $\mathcal{P}(C = L1 \mid pred = L1) = 0.866$ while $\mathcal{P}(C = L2 \mid pred = L1) = 0.132$.
    \label{tab:full_confusionMatrix}
    }
\end{SCtable}

\section{Conclusion}
\par{
    Based on the results shown in figure \ref{fig:referenceExperiments}, it was decided to perform the weakly supervised experiments with the model based on VGG16 FCN8 with one context slice.
    The reference performance metric to compare experiments with models trained on weakly supervised data is $\text{Dice}_{wi}=0,76$.
}


