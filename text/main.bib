@inproceedings{Nett2008,
author = {Nett, Brian and Tang, Jie and Leng, Shuai and Chen, Guang-Hong},
booktitle = {Medical Imaging 2008: Physics of Medical Imaging},
doi = {10.1117/12.771294},
editor = {Hsieh, Jiang and Samei, Ehsan},
publisher = {SPIE},
title = {{Tomosynthesis via total variation minimization reconstruction and prior image constrained compressed sensing ({\{}PICCS{\}}) on a C-arm system}},
url = {https://doi.org/10.1117/12.771294},
year = {2008}
}
@techreport{Klinder2008,
abstract = {Including prior shape in the form of anatomical models is a well-known approach for improving segmentation results in medical images. Currently, most approaches are focused on the modeling and segmentation of individual objects. In case of object constellations, a simultaneous segmentation of the ensemble that uses not only prior knowledge of individual shapes but also additional information about spatial relations between the objects is often beneficial. In this paper, we present a two-scale framework for the modeling and segmentation of the spine as an example for object constellations. The global spine shape is expressed as a consecution of local vertebra coordinate systems while individual vertebrae are modeled as triangulated surface meshes. Adaptation is performed by attracting the model to image features but restricting the attraction to a former learned shape. With the developed approach, we obtained a segmentation accuracy of 1.0 mm in average for ten thoracic CT images improving former results.},
author = {Klinder, Tobias and Wolz, Robin and Lorenz, Cristian and Franz, Astrid and Ostermann, J{\"{o}}rn},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klinder et al. - 2008 - LNCS 5241 - Spine Segmentation Using Articulated Shape Models.pdf:pdf},
title = {{LNCS 5241 - Spine Segmentation Using Articulated Shape Models}},
year = {2008}
}
@article{Selvaraju2016,
archivePrefix = {arXiv},
arxivId = {1610.02391},
author = {Selvaraju, Ramprasaath R and Das, Abhishek and Vedantam, Ramakrishna and Cogswell, Michael and Parikh, Devi and Batra, Dhruv},
eprint = {1610.02391},
journal = {CoRR},
title = {{Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization}},
url = {http://arxiv.org/abs/1610.02391},
volume = {abs/1610.0},
year = {2016}
}
@article{Laradji2020,
abstract = {Instance segmentation methods often require costly per-pixel labels. We propose a method that only requires point-level annotations. During training, the model only has access to a single pixel label per object, yet the task is to output full segmentation masks. To address this challenge, we construct a network with two branches: (1) a localization network (L-Net) that predicts the location of each object; and (2) an embedding network (E-Net) that learns an embedding space where pixels of the same object are close. The segmentation masks for the located objects are obtained by grouping pixels with similar embeddings. At training time, while L-Net only requires point-level annotations, E-Net uses pseudo-labels generated by a class-agnostic object proposal method. We evaluate our approach on PASCAL VOC, COCO, KITTI and CityScapes datasets. The experiments show that our method (1) obtains competitive results compared to fully-supervised methods in certain scenarios; (2) outperforms fully- and weakly- supervised methods with a fixed annotation budget; and (3) is a first strong baseline for instance segmentation with point-level supervision.},
archivePrefix = {arXiv},
arxivId = {arXiv:1906.06392v1},
author = {Laradji, Issam H. and Rostamzadeh, Negar and Pinheiro, Pedro O. and Vazquez, David and Schmidt, Mark},
doi = {10.1109/icip40778.2020.9190782},
eprint = {arXiv:1906.06392v1},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laradji et al. - 2020 - Proposal-Based Instance Segmentation With Point Supervision.pdf:pdf},
number = {1},
pages = {2126--2130},
title = {{Proposal-Based Instance Segmentation With Point Supervision}},
year = {2020}
}
@article{McEver2020,
abstract = {Current state of the art methods for generating semantic segmentation rely heavily on a large set of images that have each pixel labeled with a class of interest label or background. Coming up with such labels, especially in domains that require an expert to do annotations, comes at a heavy cost in time and money. Several methods have shown that we can learn semantic segmentation from less expensive image-level labels, but the effectiveness of point level labels, a healthy compromise between all pixels labelled and none, still remains largely unexplored. This paper presents a novel procedure for producing semantic segmentation from images given some point level annotations. This method includes point annotations in the training of a convolutional neural network (CNN) for producing improved localization and class activation maps. Then, we use another CNN for predicting semantic affinities in order to propagate rough class labels and create pseudo semantic segmentation labels. Finally, we propose training a CNN that is normally fully supervised using our pseudo labels in place of ground truth labels, which further improves performance and simplifies the inference process by requiring just one CNN during inference rather than two. Our method achieves state of the art results for point supervised semantic segmentation on the PASCAL VOC 2012 dataset $\backslash$cite{\{}everingham2010pascal{\}}, even outperforming state of the art methods for stronger bounding box and squiggle supervision.},
archivePrefix = {arXiv},
arxivId = {2007.05615},
author = {McEver, R. Austin and Manjunath, B. S.},
eprint = {2007.05615},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McEver, Manjunath - 2020 - PCAMs Weakly Supervised Semantic Segmentation Using Point Supervision.pdf:pdf},
title = {{PCAMs: Weakly Supervised Semantic Segmentation Using Point Supervision}},
url = {http://arxiv.org/abs/2007.05615},
year = {2020}
}
@article{Cicek2016,
archivePrefix = {arXiv},
arxivId = {1606.06650},
author = {{\c{C}}i{\c{c}}ek, {\"{O}}zg{\"{u}}n and Abdulkadir, Ahmed and Lienkamp, Soeren S and Brox, Thomas and Ronneberger, Olaf},
eprint = {1606.06650},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\c{C}}i{\c{c}}ek et al. - 2016 - 3D U-Net Learning Dense Volumetric Segmentation from Sparse Annotation.pdf:pdf},
journal = {CoRR},
keywords = {Segmentation,Sparse annotation},
mendeley-tags = {Segmentation,Sparse annotation},
title = {{3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation}},
url = {http://arxiv.org/abs/1606.06650},
volume = {abs/1606.0},
year = {2016}
}
@article{Vania2019,
abstract = {There has been a significant increase from 2010 to 2016 in the number of people suffering from spine problems. The automatic image segmentation of the spine obtained from a computed tomography (CT) image is important for diagnosing spine conditions and for performing surgery with computer-assisted surgery systems. The spine has a complex anatomy that consists of 33 vertebrae, 23 intervertebral disks, the spinal cord, and connecting ribs. As a result, the spinal surgeon is faced with the challenge of needing a robust algorithm to segment and create a model of the spine. In this study, we developed a fully automatic segmentation method to segment the spine from CT images, and we compared our segmentation results with reference segmentations obtained by well-known methods. We use a hybrid method. This method combines the convolutional neural network (CNN) and fully convolutional network (FCN), and utilizes class redundancy as a soft constraint to greatly improve the segmentation results. The proposed method was found to significantly enhance the accuracy of the segmentation results and the system processing time. Our comparison was based on 12 measurements: the Dice coefficient (94$\backslash$$\backslash${\%}), Jaccard index (93$\backslash$$\backslash${\%}), volumetric similarity (96$\backslash$$\backslash${\%}), sensitivity (97$\backslash$$\backslash${\%}), specificity (99$\backslash$$\backslash${\%}), precision (over segmentation 8.3 and under segmentation 2.6), accuracy (99$\backslash$$\backslash${\%}), Matthews correlation coefficient (0.93), mean surface distance (0.16 mm), Hausdorff distance (7.4 mm), and global consistency error (0.02). We experimented with CT images from 32 patients, and the experimental results demonstrated the efficiency of the proposed method.HighlightsA method to enhance the accuracy of spine segmentation from CT data was proposed.The proposed method uses Convolutional Neural Network via redundant generation of class labels.Experiments show the segmentation accuracy has been enhanced.},
author = {Vania, Malinda and Mureja, Dawit and Lee, Deukhee},
doi = {10.1016/j.jcde.2018.05.002},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vania, Mureja, Lee - 2019 - Automatic spine segmentation from CT images using Convolutional Neural Network via redundant generation of c.pdf:pdf},
issn = {2288-5048},
journal = {Journal of Computational Design and Engineering},
number = {2},
pages = {224--232},
title = {{Automatic spine segmentation from CT images using Convolutional Neural Network via redundant generation of class labels}},
url = {https://doi.org/10.1016/j.jcde.2018.05.002},
volume = {6},
year = {2019}
}
@techreport{Suzani,
abstract = {Segmentation of vertebral structures in magnetic resonance (MR) images is challenging because of poor contrast between bone surfaces and surrounding soft tissue. This paper describes a semi-automatic method for segmenting vertebral bodies in multi-slice MR images. In order to achieve a fast and reliable segmentation, the method takes advantage of the correlation between shape and pose of different vertebrae in the same patient by using a statistical multi-vertebrae anatomical shape+pose model. Given a set of MR images of the spine, we initially reduce the intensity inhomogeneity in the images by using an intensity-correction algorithm. Then a 3D anisotropic diffusion filter smooths the images. Afterwards, we extract edges from a relatively small region of the pre-processed image with a simple user interaction. Subsequently, an iterative Expectation Maximization technique is used to register the statistical multi-vertebrae anatomical model to the extracted edge points in order to achieve a fast and reliable segmentation for lumbar vertebral bodies. We evaluate our method in terms of speed and accuracy by applying it to volumetric MR images of the spine acquired from nine patients. Quantitative and visual results demonstrate that the method is promising for segmentation of vertebral bodies in volumetric MR images.},
author = {Suzani, Amin and Rasoulian, Abtin and Fels, Sidney and Rohling, Robert N and Abolmaesumi, Purang},
doi = {https://doi.org/10.1117/12.2043847},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suzani et al. - Unknown - Semi-automatic Segmentation of Vertebral Bodies in Volumetric MR Images Using a Statistical ShapePose Model.pdf:pdf},
keywords = {Segmentation,multi-vertebrae anatomical model,vertebral body,volumetric MR image},
title = {{Semi-automatic Segmentation of Vertebral Bodies in Volumetric MR Images Using a Statistical Shape+Pose Model}},
url = {https://www.researchgate.net/publication/269313420{\_}Semi-automatic{\_}segmentation{\_}of{\_}vertebral{\_}bodies{\_}in{\_}volumetric{\_}MR{\_}images{\_}using{\_}a{\_}statistical{\_}shapepose{\_}model}
}
@techreport{Lu2018,
abstract = {The high prevalence of spinal stenosis results in a large volume of MRI imaging, yet interpretation can be time-consuming with high inter-reader variability even among the most specialized radiologists. In this paper, we develop an efficient methodology to leverage the subject-matter-expertise stored in large-scale archival reporting and image data for a deep-learning approach to fully-automated lumbar spinal stenosis grading. Specifically, we introduce three major contributions: (1) a natural-language-processing scheme to extract level-by-level ground-truth labels from free-text radiology reports for the various types and grades of spinal stenosis (2) accurate vertebral segmentation and disc-level localization using a U-Net architecture combined with a spine-curve fitting method, and (3) a multi-input, multi-task, and multi-class convolutional neural network to perform central canal and foraminal stenosis grading on both axial and sagittal imaging series inputs with the extracted report-derived labels applied to corresponding imaging level segments. This study uses a large dataset of 22796 disc-levels extracted from 4075 patients. We achieve state-of-the-art performance on lumbar spinal stenosis classification and expect the technique will increase both radiology workflow efficiency and the perceived value of radiology reports for referring clinicians and patients.},
author = {Lu, Jen-Tang and Pedemonte, Stefano and Bizzo, Bernardo and Doyle, Sean and Andriole, Katherine P and Michalski, Mark H and {Gilberto Gonzalez}, R and Pomerantz, Stuart R},
booktitle = {Proceedings of Machine Learning Research},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2018 - DEEP SPINE AUTOMATED LUMBAR VERTEBRAL SEGMENTATION, DISC-LEVEL DESIGNATION, AND SPINAL STENOSIS GRADING USING DEEP LE.pdf:pdf},
pages = {1--16},
title = {{DEEP SPINE: AUTOMATED LUMBAR VERTEBRAL SEGMENTATION, DISC-LEVEL DESIGNATION, AND SPINAL STENOSIS GRADING USING DEEP LEARNING}},
volume = {85},
year = {2018}
}
@article{Lessmann2018,
abstract = {Precise segmentation and anatomical identification of the vertebrae provides the basis for automatic analysis of the spine, such as detection of vertebral compression fractures or other abnormalities. Most dedicated spine CT and MR scans as well as scans of the chest, abdomen or neck cover only part of the spine. Segmentation and identification should therefore not rely on the visibility of certain vertebrae or a certain number of vertebrae. We propose an iterative instance segmentation approach that uses a fully convolutional neural network to segment and label vertebrae one after the other, independently of the number of visible vertebrae. This instance-by-instance segmentation is enabled by combining the network with a memory component that retains information about already segmented vertebrae. The network iteratively analyzes image patches, using information from both image and memory to search for the next vertebra. To efficiently traverse the image, we include the prior knowledge that the vertebrae are always located next to each other, which is used to follow the vertebral column. This method was evaluated with five diverse datasets, including multiple modalities (CT and MR), various fields of view and coverages of different sections of the spine, and a particularly challenging set of low-dose chest CT scans. The proposed iterative segmentation method compares favorably with state-of-the-art methods and is fast, flexible and generalizable.},
archivePrefix = {arXiv},
arxivId = {1804.04383},
author = {Lessmann, Nikolas and van Ginneken, Bram and de Jong, Pim A. and I{\v{s}}gum, Ivana},
doi = {10.1016/j.media.2019.02.005},
eprint = {1804.04383},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lessmann et al. - 2018 - Iterative fully convolutional neural networks for automatic vertebra segmentation and identification.pdf:pdf},
keywords = {Spine segmentation},
mendeley-tags = {Spine segmentation},
month = {apr},
title = {{Iterative fully convolutional neural networks for automatic vertebra segmentation and identification}},
url = {http://arxiv.org/abs/1804.04383 http://dx.doi.org/10.1016/j.media.2019.02.005},
year = {2018}
}
@article{Ronneberger2015,
annote = {Original article about U-Net.

Stress on low data volume needed.},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
eprint = {1505.04597},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:pdf;:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation(2).pdf:pdf},
journal = {CoRR},
keywords = {Medical,Segmentation},
mendeley-tags = {Medical,Segmentation},
title = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
url = {http://arxiv.org/abs/1505.04597},
volume = {abs/1505.0},
year = {2015}
}
@article{Huang2013,
author = {Huang, Jing and Zhang, Yunwan and Ma, Jianhua and Zeng, Dong and Bian, Zhaoying and Niu, Shanzhou and Feng, Qianjin and Liang, Zhengrong and Chen, Wufan},
doi = {10.1371/journal.pone.0079709},
editor = {Wang, Ge},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2013 - Iterative Image Reconstruction for Sparse-View {\{}CT{\}} Using Normal-Dose Image Induced Total Variation Prior.pdf:pdf},
journal = {{\{}PLoS{\}} {\{}ONE{\}}},
keywords = {Tomography},
mendeley-tags = {Tomography},
month = {nov},
number = {11},
pages = {e79709},
publisher = {Public Library of Science ({\{}PLoS{\}})},
title = {{Iterative Image Reconstruction for Sparse-View {\{}CT{\}} Using Normal-Dose Image Induced Total Variation Prior}},
url = {https://doi.org/10.1371/journal.pone.0079709},
volume = {8},
year = {2013}
}
@article{Chan2020,
abstract = {Recently proposed methods for weakly-supervised semantic segmentation have achieved impressive performance in predicting pixel classes despite being trained with only image labels which lack positional information. Because image annotations are cheaper and quicker to generate, weak supervision is more practical than full supervision for training segmentation algorithms. These methods have been predominantly developed to solve the background separation and partial segmentation problems presented by natural scene images and it is unclear whether they can be simply transferred to other domains with different characteristics, such as histopathology and satellite images, and still perform well. This paper evaluates state-of-the-art weakly-supervised semantic segmentation methods on natural scene, histopathology, and satellite image datasets and analyzes how to determine which method is most suitable for a given dataset. Our experiments indicate that histopathology and satellite images present a different set of problems for weakly-supervised semantic segmentation than natural scene images, such as ambiguous boundaries and class co-occurrence. Methods perform well for datasets they were developed on, but tend to perform poorly on other datasets. We present some practical techniques for these methods on unseen datasets and argue that more work is needed for a generalizable approach to weakly-supervised semantic segmentation. Our full code implementation is available on GitHub: https://github.com/lyndonchan/wsss-analysis.},
archivePrefix = {arXiv},
arxivId = {1912.11186},
author = {Chan, Lyndon and Hosseini, Mahdi S. and Plataniotis, Konstantinos N.},
doi = {10.1007/s11263-020-01373-4},
eprint = {1912.11186},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chan, Hosseini, Plataniotis - 2020 - A Comprehensive Analysis of Weakly-Supervised Semantic Segmentation in Different Image Domains.pdf:pdf},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Convolutional neural network,Deep learning,Digital pathology,Natural imaging,Satellite imaging,Self-supervised Learning,Weakly supervised semantic segmentation},
title = {{A Comprehensive Analysis of Weakly-Supervised Semantic Segmentation in Different Image Domains}},
year = {2020}
}
@article{DasCLuciaMS2017,
abstract = {Multicolored proteins have allowed the color coding of cancer cells growing in vivo and enabled the distinction of host from tumor with single-cell resolution. Non-invasive imaging with fluorescent proteins enabled follow the dynamics of metastatic cancer to be followed in real time in individual animals. Non-invasive imaging of cancer cells expressing fluorescent proteins has enabled the real-time determination of efficacy of candidate antitumor and antimetastatic agents in mouse models. The use of fluorescent proteins to differentially label cancer cells in the nucleus and cytoplasm allow visualization of the nuclear–cytoplasmic dynamics of cancer cells in vivo, mitosis, apoptosis, cell-cycle position and differential behavior of nucleus and cytoplasm such as occurs during cancer-cell deformation and extravasation. Recent applications of the technology described here include linking fluorescent proteins with cell-cycle-specific proteins (FUCCI) such that the cells change color from red to green as they transit from G1 to S phases. With the macro and micro imaging technologies described here, essentially any in vivo process can be imaged, enabling the new field of in vivo cell biology using fluorescent proteins.},
author = {doi:10.1016/j.brs.2016.03.010 {Perera T, George MS, Grammer G, Janicak PG, Pascual-Leone A}, Wirecki TS. The Clinical TMS Society Consensus Review and Treatment Recommendations for TMS Therapy for Major Depressive Disorder. Brain Stimul. 2016;9(3):336-346.},
doi = {10.1088/0031-9155/61/8/3009.3D},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perera T, George MS, Grammer G, Janicak PG, Pascual-Leone A - 2017 - 3D–2D image registration for target localization in spine surg(2).pdf:pdf},
isbn = {2163684814},
journal = {Physiology {\&} behavior},
keywords = {determination,protein crystallography,protein data bank,r -factor,resolution,restraints,structure,structure interpretation,structure quality,structure refinement,structure validation,ultrasound},
mendeley-tags = {ultrasound},
number = {1},
pages = {139--148},
title = {{3D–2D image registration for target localization in spine surgery: investigation of similarity metrics providing robustness to content mismatch}},
volume = {176},
year = {2017}
}
@article{Hyun2018,
author = {Hyun, Chang Min and Kim, Hwa Pyung and Lee, Sung Min and Lee, Sungchul and Seo, Jin Keun},
doi = {10.1088/1361-6560/aac71a},
file = {:home/jan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyun et al. - 2018 - Deep learning for undersampled {\{}MRI{\}} reconstruction.pdf:pdf},
journal = {Physics in Medicine {\&} Biology},
keywords = {Reconstruction,Tomography},
mendeley-tags = {Reconstruction,Tomography},
number = {13},
pages = {135007},
publisher = {{\{}IOP{\}} Publishing},
title = {{Deep learning for undersampled {\{}MRI{\}} reconstruction}},
url = {https://doi.org/10.1088/1361-6560/aac71a},
volume = {63},
year = {2018}
}
