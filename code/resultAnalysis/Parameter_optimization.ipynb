{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset analysis "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "import seaborn as sns\n",
    "import json\n",
    "from matplotlib import cm\n",
    "from pprint import pformat\n",
    "import json\n",
    "\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "sns.color_palette(\"colorblind\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_json(filename : str) -> Dict:\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_path_raw = r'/media/jan/DataStorage/ProjectData/temp/results_weighted_dataset_X_contrast_3'\n",
    "base_path = [os.path.abspath(base_path_raw.replace('X', str(i))) for i in range(3)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_results_frame(dim : int, csv_name = 'parameter_overview') -> pd.DataFrame:\n",
    "    model_folders = [os.path.join(base_path[dim], o) for o in os.listdir(base_path[dim]) if os.path.isdir(os.path.join(base_path[dim],o)) and not o.startswith('.')]\n",
    "    results = list()\n",
    "    for folder in model_folders:\n",
    "        try:\n",
    "            r = load_json(os.path.join(folder, r'score_dict_final.json'))\n",
    "        except:\n",
    "            print(f'No experimant dict for folder {folder}.')\n",
    "            continue\n",
    "        exp_dict = load_json(os.path.join(folder, f'exp_dict.json'))\n",
    "        r.update({\n",
    "            'model_base' : exp_dict['model']['base'],\n",
    "            'context_span' : exp_dict['dataset']['context_span'],\n",
    "            'blob_points' : exp_dict['dataset']['blob_points'],\n",
    "            'bg_points' : exp_dict['dataset']['bg_points'],\n",
    "            'loss' : exp_dict['model']['loss'],\n",
    "            'foldername' : folder.split('/')[-1],\n",
    "            'sources' : exp_dict['dataset']['sources'],\n",
    "            'separation_loss' : ('separation_loss' in exp_dict['model']['loss']),\n",
    "            'prior_extend' : ('prior_extend' in exp_dict['model']['loss']),\n",
    "            'weighted_point_loss' : ('rot_point_loss_multi_weighted' in exp_dict['model']['loss'])\n",
    "        })\n",
    "        results.append(r)\n",
    "\n",
    "    results = pd.DataFrame(results).sort_values(['test_weighted_dice', 'test_dice'], ascending = False).reset_index(drop=True)\n",
    "    results.to_csv(f'{csv_name}_dim{dim}')\n",
    "    return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_dict = {dim : get_results_frame(dim) for dim in range(3)}\n",
    "results_dict[0][['context_span', 'blob_points', 'bg_points', 'loss', 'separation_loss', 'weighted_point_loss', 'prior_extend', 'sources', 'test_weighted_dice', 'foldername']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_dict[1][['context_span', 'blob_points', 'bg_points', 'loss', 'separation_loss', 'weighted_point_loss', 'prior_extend', 'sources', 'test_weighted_dice', 'foldername']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results_dict[2][['context_span', 'blob_points', 'bg_points', 'loss', 'separation_loss', 'weighted_point_loss', 'prior_extend', 'sources', 'test_weighted_dice', 'foldername']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "investigate influence of leaving out a loss term"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "ax = plt.subplot(3,1,1)\n",
    "res_select = results_dict[0].query('context_span == 1 & blob_points == 3 & bg_points == 10')\n",
    "res_select.plot.barh(x = 'weighted_point_loss', y = ['test_weighted_dice', 'test_dice'], ax=plt.gca(), legend=False)\n",
    "plt.title('Transverse slice model performance')\n",
    "plt.yticks(ticks = [True, False], labels = ['weighted point loss', 'non-weighted point loss'])\n",
    "plt.ylabel('')\n",
    "\n",
    "\n",
    "plt.subplot(3,1,2, sharex = ax)\n",
    "res_select = results_dict[1].query('context_span == 1 & blob_points == 5 & bg_points == 5')\n",
    "res_select.plot.barh(x = 'weighted_point_loss', y = ['test_weighted_dice', 'test_dice'], ax=plt.gca(), legend=False)\n",
    "plt.title('dim 1 slice model performance')\n",
    "plt.yticks(ticks = [True, False], labels = ['weighted point loss', 'non-weighted point loss'])\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.subplot(3,1,3, sharex = ax)\n",
    "res_select = results_dict[2].query('context_span == 1 & blob_points == 5 & bg_points == 5 & separation_loss')\n",
    "res_select.plot.barh(x = 'weighted_point_loss', y = ['test_weighted_dice', 'test_dice'], ax=plt.gca())\n",
    "plt.title('Dim 2 slice model performance')\n",
    "plt.yticks(ticks = [True, False], labels = ['weighted point loss', 'non-weighted point loss'])\n",
    "plt.ylabel('')\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.20),\n",
    "          ncol=2)\n",
    "\n",
    "plt.suptitle('weighted point loss vs non-weighted point loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('weightedvsnonweighted.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "ax = plt.subplot(3,1,1)\n",
    "res_select = results_dict[0].query('context_span == 1 & blob_points == 5 & bg_points == 5')\n",
    "res_select.plot.barh(x = 'loss', y = ['test_weighted_dice', 'test_dice'], ax=plt.gca(), legend=False)\n",
    "plt.title('Transverse slice model performance')\n",
    "plt.yticks(ticks = [2, 1, 0], labels = ['no prior extend', 'no separation loss', '4 loss compontents'])\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.subplot(3,1,2, sharex = ax)\n",
    "res_select = results_dict[2].query('context_span == 1 & blob_points == 5 & bg_points == 5 & not weighted_point_loss')\n",
    "res_select.plot.barh(x = 'loss', y = ['test_weighted_dice', 'test_dice'], ax=plt.gca())\n",
    "plt.title('Sagittal slice model performance')\n",
    "plt.yticks(ticks = [1, 0], labels = ['no separation loss', '4 loss compontents'])\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.50),\n",
    "          ncol=2)\n",
    "\n",
    "plt.suptitle('Influence of loss components')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('Losscomponents.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "res_select = results_dict[1].query('context_span == 1 & weighted_point_loss == False & separation_loss')\n",
    "res_select = res_select[-res_select.foldername.str.contains('_')]\n",
    "res_1 = res_select.pivot(index = 'blob_points', columns = 'bg_points', values = 'test_weighted_dice')\n",
    "res_select = results_dict[2].query('context_span == 1 & weighted_point_loss == False & separation_loss')\n",
    "res_select = res_select[-res_select.foldername.str.contains('_')]\n",
    "res_2 = res_select.pivot(index = 'blob_points', columns = 'bg_points', values = 'test_weighted_dice')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1)\n",
    "ax = res_1.plot(ax = plt.gca(), legend=False, linestyle = ':', marker = '*')\n",
    "plt.xlabel('weighted dice score')\n",
    "plt.title('Coronal slice model performance')\n",
    "ax.set_ylabel(\"weighted dice score\")\n",
    "plt.subplot(2,1,2, sharex = ax, sharey = ax)\n",
    "ax = res_2.plot(ax = plt.gca(), linestyle = ':', marker = '*')\n",
    "plt.title('Sagittal slice model performance')\n",
    "ax.set_ylabel(\"weighted dice score\")\n",
    "\n",
    "plt.suptitle('Number of blob_points')\n",
    "\n",
    "plt.savefig('BlobPoints_influence.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reconstruct_foldernames = []\n",
    "\n",
    "res_select = results_dict[0].query('context_span == 1 & weighted_point_loss == False & separation_loss & blob_points == 1')\n",
    "res_select = res_select[-res_select.foldername.str.contains('_')]\n",
    "print(res_select[['foldername', 'test_weighted_dice']])\n",
    "reconstruct_foldernames.append(res_select.foldername.iloc[0])\n",
    "res_select = results_dict[1].query('context_span == 1 & weighted_point_loss == False & separation_loss & bg_points == 3 & blob_points == 1')\n",
    "res_select = res_select[-res_select.foldername.str.contains('_')]\n",
    "print(res_select[['foldername', 'test_weighted_dice']])\n",
    "reconstruct_foldernames.append(res_select.foldername.iloc[0])\n",
    "res_select = results_dict[2].query('context_span == 1 & weighted_point_loss == False & separation_loss & bg_points == 3 & blob_points == 1')\n",
    "res_select = res_select[-res_select.foldername.str.contains('_')]\n",
    "print(res_select[['foldername', 'test_weighted_dice']])\n",
    "reconstruct_foldernames.append(res_select.foldername.iloc[0])\n",
    "\n",
    "\n",
    "exp_dict_reconstruct = dict()\n",
    "for i, foldername in enumerate(reconstruct_foldernames):\n",
    "    folder = os.path.join(base_path[i], foldername)\n",
    "    print(folder)\n",
    "    exp_dict = load_json(os.path.join(folder, f'exp_dict.json'))\n",
    "    exp_dict['hash'] = foldername\n",
    "    exp_dict_reconstruct[i] = exp_dict\n",
    "\n",
    "with open('exp_dict_reconstruct.json', 'w') as f:\n",
    "    json.dump(exp_dict_reconstruct, f)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "res_select.foldername.iloc[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_wd = result.pivot(index = 'context_span', columns = ['loss', 'model_base'], values = 'test_weighted_dice')\n",
    "test_wd = test_wd.reindex(sorted(test_wd.columns), axis=1)\n",
    "print(test_wd.head())\n",
    "test_wd.applymap(lambda x : round(x, 2)).to_html('test_wd.html')\n",
    "test_wd.plot(kind='bar', subplots = True, layout = (2, 3), legend = False, figsize = (12, 6), ylim = (0.5, 1))\n",
    "plt.suptitle('weighted dice score - Test')\n",
    "plt.savefig('full_test_wd.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_d = result.pivot(index = 'context_span', columns = ['loss', 'model_base'], values = 'test_dice')\n",
    "test_d = test_d.reindex(sorted(test_d.columns), axis=1)\n",
    "print(test_d.head())\n",
    "test_d.applymap(lambda x : round(x, 2)).to_html('test_d.html')\n",
    "test_d.plot(kind='bar', subplots = True, layout = (2, 3), legend = False, figsize = (12, 6), ylim = (0.5, 1))\n",
    "plt.suptitle('dice score - Test')\n",
    "plt.savefig('full_test_d.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_wd = result.pivot(index = 'context_span', columns = ['loss', 'model_base'], values = 'train_weighted_dice')\n",
    "train_wd = train_wd.reindex(sorted(train_wd.columns), axis=1)\n",
    "train_wd.applymap(lambda x : round(x, 2)).to_html('train_wd.html')\n",
    "print(train_wd)\n",
    "train_wd.plot(kind='bar', subplots = True, layout = (2, 3), legend = False, figsize = (12, 6), ylim = (0.5, 1))\n",
    "plt.suptitle('weighted dice score - Train')\n",
    "plt.savefig('full_train_wd.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_d = result.pivot(index = 'context_span', columns = ['loss', 'model_base'], values = 'test_dice')\n",
    "train_d = train_wd.reindex(sorted(train_d.columns), axis=1)\n",
    "train_d.applymap(lambda x : round(x, 2)).to_html('train_d.html')\n",
    "print(train_d)\n",
    "train_d.plot(kind='bar', subplots = True, layout = (2, 3), legend = False, figsize = (12, 6), ylim = (0.5, 1))\n",
    "plt.suptitle('dice score - Train')\n",
    "plt.savefig('train_d.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "foldername = result.query(\"context_span == 3 & loss == 'weighted_cross_entropy' & model_base == 'fcn8_vgg16'\").foldername.iloc[0]\n",
    "print(foldername)\n",
    "score_df = pd.read_csv(os.path.join(base_path[2], foldername, 'score_df.csv'), index_col=0)\n",
    "\n",
    "f, ax = plt.subplots(2)\n",
    "score_df.plot(x = 'epoch', y = 'val_weighted_dice', ax = ax[0])\n",
    "score_df.plot(x = 'epoch', y = 'train_weighted_dice', ax = ax[0])\n",
    "score_df.plot(x = 'epoch', y = 'train_loss', ax=ax[1], logy = True)\n",
    "\n",
    "plt.savefig('full_learning_curve.png')\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Myo_df = pd.read_csv(os.path.join(base_path[2], foldername, 'test_metrics_MyoSegmenTUM_df.csv'), index_col=0)\n",
    "USieg_df = pd.read_csv(os.path.join(base_path[2], foldername, 'test_metrics_USiegen_df.csv'), index_col=0)\n",
    "xVert_df = pd.read_csv(os.path.join(base_path[2], foldername, 'test_metrics_xVertSeg_df.csv'), index_col=0)\n",
    "all_df = pd.read_csv(os.path.join(base_path[2], foldername, 'test_metrics_df.csv'), index_col=0)\n",
    "\n",
    "temp = pd.DataFrame()\n",
    "for name, df in zip(['MyoSegmentum', 'USiegen', 'xVertSeg', 'total'], [Myo_df, USieg_df, xVert_df, all_df]):\n",
    "    temp[name] = df['dice']\n",
    "\n",
    "temp.plot(kind = 'barh', xlim = (.5, 1), figsize=(12, 6))\n",
    "plt.savefig('full_perSource.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "base_path_raw = r'/media/jan/DataStorage/ProjectData/temp/results_weighted_dataset_X_contrast_3'\n",
    "base_path = [os.path.abspath(base_path_raw.replace('X', str(i))) for i in range(3)]\n",
    "folders = []\n",
    "for bp in base_path:\n",
    "    model_folders = [os.path.join(bp, o) for o in os.listdir(bp) if os.path.isdir(os.path.join(bp,o)) and not o.startswith('.')]\n",
    "    folders.append(model_folders[0])\n",
    "\n",
    "folders"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "result = []\n",
    "for i in range(3):\n",
    "    r = load_json(os.path.join(folders[i], r'score_dict_final.json'))\n",
    "    exp_dict = load_json(os.path.join(folders[i], f'exp_dict.json'))\n",
    "    r.update({\n",
    "            'model_base' : exp_dict['model']['base'],\n",
    "            'context_span' : exp_dict['dataset']['context_span'],\n",
    "            'loss' : exp_dict['model']['loss'],\n",
    "            'foldername' : folder.split('/')[-1],\n",
    "            'dim' : i\n",
    "        })\n",
    "    result.append(r)\n",
    "\n",
    "result = pd.DataFrame(result).sort_values(['test_weighted_dice', 'test_dice'], ascending = False)\n",
    "result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(3):\n",
    "    Myo_df = pd.read_csv(os.path.join(folders[i], 'test_metrics_MyoSegmenTUM_df.csv'), index_col=0)\n",
    "    USieg_df = pd.read_csv(os.path.join(folders[i], 'test_metrics_USiegen_df.csv'), index_col=0)\n",
    "    xVert_df = pd.read_csv(os.path.join(folders[i], 'test_metrics_xVertSeg_df.csv'), index_col=0)\n",
    "    all_df = pd.read_csv(os.path.join(folders[i], 'test_metrics_df.csv'), index_col=0)\n",
    "\n",
    "    temp = pd.DataFrame()\n",
    "    for name, df in zip(['MyoSegmentum', 'USiegen', 'xVertSeg', 'total'], [Myo_df, USieg_df, xVert_df, all_df]):\n",
    "        temp[name] = df['dice']\n",
    "\n",
    "    temp.plot(kind = 'barh', figsize=(8, 6), title=f'dice score model for dimension {i}')\n",
    "    plt.savefig(f'dim_{i}_perSource.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(3):\n",
    "    score_df = pd.read_csv(os.path.join(folders[i], 'score_df.csv'), index_col=0)\n",
    "\n",
    "    f, ax = plt.subplots(2)\n",
    "    score_df.plot(x = 'epoch', y = 'val_weighted_dice', ax = ax[0])\n",
    "    score_df.plot(x = 'epoch', y = 'train_weighted_dice', ax = ax[0])\n",
    "    score_df.plot(x = 'epoch', y = 'train_loss', ax=ax[1], logy = False)\n",
    "    plt.suptitle(f'learning curve dimension {i}')\n",
    "\n",
    "    plt.savefig(f'weakly_dim{i}_learning_curve.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('thesis': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "interpreter": {
   "hash": "e10d22ba302c321b21b9b695683178e0f8a286f8e94ccf14f116b4768e2ea1b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}